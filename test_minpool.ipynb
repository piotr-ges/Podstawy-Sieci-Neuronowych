{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.803805100Z",
     "start_time": "2024-11-24T11:53:08.749349300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models.detection import transform\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.nn.functional import max_pool2d\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import RandomChoice\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c287e69a146fa024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.814525300Z",
     "start_time": "2024-11-24T11:53:11.803805100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs_number = 100\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ab1129-c9ff-41c0-9dc0-bf6e972dae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_pool2d(input_tensor, kernel_size, stride=None, padding=0):\n",
    "    #jeśli jest co padować\n",
    "    if padding > 0:\n",
    "        input_tensor = F.pad(input_tensor, (padding, padding, padding, padding), value=float('inf'))\n",
    "        \n",
    "    #odwrucenie wejścia\n",
    "    neg_tensor = -input_tensor\n",
    "    \n",
    "    # Wykonujemy max pooling na zanegowanym tensorze\n",
    "    max_pooled = F.max_pool2d(neg_tensor, kernel_size, stride=stride)\n",
    "    \n",
    "    # Przywracamy znaki do oryginalnych (zamiana na min pooling)\n",
    "    return -max_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a9316297d6d2af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.814525300Z",
     "start_time": "2024-11-24T11:53:11.807396900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Create dataset\n",
    "class PlayingCardDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be33c020-6a30-4b0d-85c5-25bc1396e127",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.823120300Z",
     "start_time": "2024-11-24T11:53:11.813025Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#Model\n",
    "class CardClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=53):\n",
    "        super(CardClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)  # Dostosuj rozmiar wejścia do wymiaru po pooling\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = min_pool2d(F.relu(self.bn1(self.conv1(x))), kernel_size=2, stride=2, padding=1)\n",
    "        x = min_pool2d(F.relu(self.bn2(self.conv2(x))), kernel_size=2, stride=2, padding=1)\n",
    "        x = min_pool2d(F.relu(self.bn3(self.conv3(x))), kernel_size=2, stride=2, padding=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout2(x)\n",
    "        output = self.fc3(x)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f920b403317c00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.865151600Z",
     "start_time": "2024-11-24T11:53:11.816027300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CardClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCardClassifier\u001b[49m(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m53\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CardClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "model = CardClassifier(num_classes=53)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639032c82fee9eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.874163400Z",
     "start_time": "2024-11-24T11:53:11.865654600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2581d75cf1864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.921275400Z",
     "start_time": "2024-11-24T11:53:11.870160300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), #Resize to 128x128\n",
    "    RandomChoice([  # Wybór jednej z poniższych transformacji z równym prawdopodobieństwem\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.RandomVerticalFlip(p=1.0),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2)]),  # Color adjustments\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), #Resize to 128x128\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_folder = r'./95_2.5_2.5/train'\n",
    "valid_folder = r'./95_2.5_2.5/val'\n",
    "test_folder = r'./95_2.5_2.5/test'\n",
    "\n",
    "train_dataset = PlayingCardDataset(train_folder, transform=transform_train)\n",
    "val_dataset = PlayingCardDataset(valid_folder, transform=transform)\n",
    "test_dataset = PlayingCardDataset(test_folder, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fd318-af37-46e0-befa-fe3f51881701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.926279600Z",
     "start_time": "2024-11-24T11:53:11.899384600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "\n",
    "class EarlyStopping():\n",
    "  def __init__(self, patience=4, min_delta=0, restore_best_weights=True):\n",
    "    self.patience = patience\n",
    "    self.min_delta = min_delta\n",
    "    self.restore_best_weights = restore_best_weights\n",
    "    self.best_model = None\n",
    "    self.best_loss = None\n",
    "    self.counter = 0\n",
    "    self.status = \"\"\n",
    "\n",
    "  def __call__(self, model, val_loss):\n",
    "    if self.best_loss == None:\n",
    "      self.best_loss = val_loss\n",
    "      self.best_model = copy.deepcopy(model)\n",
    "    elif self.best_loss - val_loss > self.min_delta:\n",
    "      self.best_loss = val_loss\n",
    "      self.counter = 0\n",
    "      self.best_model.load_state_dict(model.state_dict())\n",
    "    elif self.best_loss - val_loss < self.min_delta:\n",
    "      self.counter += 1\n",
    "      if self.counter >= self.patience:\n",
    "        self.status = f\"Stopped on {self.counter}\"\n",
    "        if self.restore_best_weights:\n",
    "          model.load_state_dict(self.best_model.state_dict())\n",
    "        return True\n",
    "    self.status = f\"{self.counter}/{self.patience}\"\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69991bd878075cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:53:11.941825100Z",
     "start_time": "2024-11-24T11:53:11.904256800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86267436fbf0abe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T12:00:16.342522300Z",
     "start_time": "2024-11-24T11:53:11.945354500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = epochs_number\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "model = CardClassifier(num_classes=53)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "es = EarlyStopping(patience=patience)\n",
    "\n",
    "epoch = 0\n",
    "done = False\n",
    "while epoch < num_epochs and not done:\n",
    "    epoch += 1\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc='Training loop'):\n",
    "        # Move inputs and labels to the device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Validation loop'):\n",
    "            # Move inputs and labels to the device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "         \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")\n",
    "    \n",
    "     # Check early stopping criteria\n",
    "    done = es(model, val_loss)\n",
    "    print(f\"Early Stopping: {es.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd93e1efe556451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T12:00:16.428825Z",
     "start_time": "2024-11-24T12:00:16.338913400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualize Losses\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba489a2f89204b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T12:00:16.714874100Z",
     "start_time": "2024-11-24T12:00:16.425765200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the Accuracy of the Model using test data\n",
    "\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)  # Get the class index with the highest probability\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6c4de6c55cdf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T12:00:34.051471500Z",
     "start_time": "2024-11-24T12:00:33.968070400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"card_classifier93.21%.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60629fc6bdac89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T12:00:16.715872600Z",
     "start_time": "2024-11-24T12:00:16.713374Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f9c12-d314-4631-950a-919217cdcadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff231df-ca69-45dd-acbb-8ab3e6decff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd64866-606c-49c2-8fff-5fc1c871d4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
